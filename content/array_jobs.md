# Parallelize using Slurm Array jobs

Slurm array jobs are jobs, that are run multiple times, with the same settings.
a slurm batch script with an array job looks something like:

```slurm
#!/bin/bash
#SBATCH --job-name=my_array_job
#SBATCH --array=2-100:2
#SBATCH --output=output_%A_%a.txt
#SBATCH --error=error_%A_%a.txt

# Your job commands go here
# You can use the environment variable SLURM_ARRAY_TASK_ID to get the current task ID
# load whatever modules or environments you need before running your actual command

# Example command: replace with your actual command
your_command --parameter $SLURM_ARRAY_TASK_ID
```

where `--array=2-100:2` creates 50 jobs numbered from 2 to 100 with a step size of 2
(the step size defaults to 1 if omitted). `%A` and `%a` in output and error indicate
the jobID and arrayID of the job respectively. The only difference in these jobs is the
environment variable `SLURM_ARRAY_TASK_ID` which is set to the array id of the job
and can be used to select what to calculate in this job.

We can use this variable to tell our program which element to use in this job, done in the above example by passing the `$SLURM_ARRAY_TASK_ID` as the parameter argument for the
program we run.

```{exercise} Parallel-2: Create a slurm script and run it.
For our example we will need to adapt the above script a bit.
First, we will need to run it for only four different values, as we only have four different
countries. Second, we need to start our array at 0 since python uses zero-based indexing
or we will need to adapt our code to change this.

Finally, we don't have any argument parsing, but need to provide the input parameter directly to the script as in `python long_code.py 1`

Build the sbatch script that we need to run the code for our 4 countries and run it on your cluster
```

````{solution} Solution: Parallel-1
Here is a script that should be able to run on your cluster:

```slurm
#!/bin/bash
#SBATCH --job-name=my_array_job
#SBATCH --array=0-3
#SBATCH --output=output_%A_%a.txt
#SBATCH --error=error_%A_%a.txt

# We assume, that python3 runs out of the box on your cluster, if not, you will have to
# add a command here that makes the python3 command available on your cluster

# Example command: replace with your actual command
python3 long_code.py $SLURM_ARRAY_TASK_ID
```

````
